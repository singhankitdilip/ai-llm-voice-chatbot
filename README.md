ğŸ™ï¸ AI Voice Chatbot (Offline, Free)

A fully local AI Voice Assistant built with Whisper + LLaMA + Piper, running 100% offline.

This project allows you to talk to AI using your microphone and hear spoken responses, with no cloud APIs and no usage limits.

ğŸ§  Tech Stack
Frontend

âš›ï¸ React (Vite)

ğŸ¤ Web Audio API (MediaRecorder)

ğŸŒŠ Animated speaking/listening UI

ğŸ“ Runs on http://localhost:5173

Backend (Voice Pipeline)

ğŸ—£ Whisper (faster-whisper) â†’ Speech to Text

ğŸ§  LLaMA 3.2 3B (Ollama) â†’ AI Brain

ğŸ”Š Piper TTS â†’ Text to Speech

ğŸš€ Express.js â†’ Orchestration API

ğŸ“ Runs on http://localhost:7000

ğŸ— Architecture
Frontend (5173)
   â†“
Express Voice Server (7000)
   â†“
Whisper STT (4000)
   â†“
Ollama LLaMA (11434)
   â†“
Piper TTS (5000)

ğŸ“ Project Structure
ai-voice-chatbot/
â”œâ”€ frontend/                 # Vite + React (5173)
â”œâ”€ server/                   # Express Voice Server (7000)
â”‚  â””â”€ index.js
â”œâ”€ whisper/                  # Whisper STT (4000)
â”‚  â”œâ”€ whisper_server.py
â”‚  â””â”€ requirements.txt
â”œâ”€ piper-server/             # Piper TTS (5000)
â”‚  â”œâ”€ piper-server.js
â”‚  â””â”€ piper/
â”‚     â”œâ”€ piper.exe
â”‚     â”œâ”€ onnxruntime.dll
â”‚     â”œâ”€ espeak-ng-data/
â”‚     â””â”€ voices/
â”‚        â”œâ”€ test_voice.onnx
â”‚        â””â”€ test_voice.onnx.json
â””â”€ README.md

âœ… Requirements
System

Windows 10/11

Node.js 18+

Python 3.10â€“3.11

FFmpeg (added to PATH)

Node
npm install -g nodemon

ğŸ§© 1ï¸âƒ£ Whisper Setup (Speech â†’ Text)
Install dependencies
cd whisper
pip install -r requirements.txt

requirements.txt
faster-whisper==1.0.3
numpy>=1.24
flask>=2.3

Run Whisper server
python whisper_server.py


Whisper runs on:

http://127.0.0.1:4000

ğŸ§© 2ï¸âƒ£ Ollama + LLaMA Setup
Install Ollama

ğŸ‘‰ https://ollama.com

Pull LLaMA model
ollama pull llama3.2:3b

Ollama API runs on
http://127.0.0.1:11434

ğŸ§© 3ï¸âƒ£ Piper Setup (Text â†’ Speech)
Folder requirements

Only these files are needed:

piper/
â”œâ”€ piper.exe
â”œâ”€ onnxruntime.dll
â”œâ”€ espeak-ng-data/
â””â”€ voices/
   â”œâ”€ test_voice.onnx
   â””â”€ test_voice.onnx.json

Run Piper server
cd piper-server
node piper-server.js


Piper runs on:

http://127.0.0.1:5000

Test Piper
curl -X POST http://127.0.0.1:5000/tts ^
  -H "Content-Type: application/json" ^
  -d "{\"text\":\"Piper is working\"}" ^
  --output test.wav

ğŸ§© 4ï¸âƒ£ Voice Server (Express)
Install dependencies
cd server
npm install

Start server
node index.js


Server runs on:

http://localhost:7000/chat


CORS is enabled for http://localhost:5173

ğŸ§© 5ï¸âƒ£ Frontend (Vite + React)
Install dependencies
cd frontend
npm install

Start frontend
npm run dev


Frontend runs on:

http://localhost:5173

ğŸ¯ How It Works

User clicks ğŸ¤ Talk to AI

Audio recorded from mic

Audio sent to Express server

Whisper converts speech â†’ text

LLaMA generates response

Piper converts response â†’ voice

Audio streamed back to browser

AI speaks ğŸ§

âš ï¸ Common Issues
âŒ CORS Error

âœ” Fixed by enabling cors() in Express

âŒ Piper not responding

âœ” Make sure piper-server.js is running
âœ” Port 5000 must be free

âŒ Whisper errors

âœ” FFmpeg must be installed
âœ” Use Python 3.10â€“3.11

ğŸš€ Features

âœ… Fully offline

âœ… No API keys

âœ… Unlimited usage

âœ… Real-time voice interaction

âœ… Animated speaking/listening UI

âœ… Short-term memory (conversation)

ğŸ”® Future Improvements

Live transcription

Streaming audio (AI speaks while thinking)

Per-user sessions

Wake word detection

Desktop app (Electron / Tauri)

ğŸ Final Notes

This project is built for learning, experimentation, and local AI apps.
You now own the entire AI voice stack â€” no limits, no lock-in.

ğŸ”¥ Enjoy building.
